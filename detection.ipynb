{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir='/home/aarke/Coding/yolov5'\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/potato_proj/detection.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39mis_available()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/potato_proj/detection.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# from pathlib import Path\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# import torchvision\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m attempt_load\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataloaders\u001b[39;00m \u001b[39mimport\u001b[39;00m LoadImages\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneral\u001b[39;00m \u001b[39mimport\u001b[39;00m non_max_suppression, scale_segments\n",
      "File \u001b[0;32m~/Coding/yolov5/models/experimental.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownloads\u001b[39;00m \u001b[39mimport\u001b[39;00m attempt_download\n\u001b[1;32m     14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSum\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m     15\u001b[0m     \u001b[39m# Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/compCV/lib/python3.11/site-packages/torch/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     Parameter \u001b[39mas\u001b[39;00m Parameter,\n\u001b[1;32m      4\u001b[0m     UninitializedParameter \u001b[39mas\u001b[39;00m UninitializedParameter,\n\u001b[1;32m      5\u001b[0m     UninitializedBuffer \u001b[39mas\u001b[39;00m UninitializedBuffer,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m DataParallel \u001b[39mas\u001b[39;00m DataParallel\n",
      "File \u001b[0;32m~/anaconda3/envs/compCV/lib/python3.11/site-packages/torch/nn/modules/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodule\u001b[39;00m \u001b[39mimport\u001b[39;00m Module\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlinear\u001b[39;00m \u001b[39mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconv\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[1;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[1;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001b[0;32m~/anaconda3/envs/compCV/lib/python3.11/site-packages/torch/nn/modules/module.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mweakref\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m Parameter\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhooks\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype\n",
      "File \u001b[0;32m~/anaconda3/envs/compCV/lib/python3.11/site-packages/torch/nn/parameter.py:13\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mself\u001b[39m, instance):\n\u001b[1;32m      9\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__instancecheck__\u001b[39m(instance) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m             \u001b[39misinstance\u001b[39m(instance, torch\u001b[39m.\u001b[39mTensor) \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(instance, \u001b[39m'\u001b[39m\u001b[39m_is_param\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m---> 13\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mParameter\u001b[39;00m(torch\u001b[39m.\u001b[39;49mTensor, metaclass\u001b[39m=\u001b[39m_ParameterMeta):\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"A kind of Tensor that is to be considered a module parameter.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m    Parameters are :class:`~torch.Tensor` subclasses, that have a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m            :ref:`locally-disable-grad-doc` for more details. Default: `True`\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'Tensor'"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import torchvision\n",
    "from models.experimental import attempt_load\n",
    "from utils.dataloaders import LoadImages\n",
    "from utils.general import non_max_suppression, scale_segments\n",
    "from utils.torch_utils import select_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'select_device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/potato_proj/detection.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/aarke/runs/detect/train13/weights/best.pt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m device \u001b[39m=\u001b[39m select_device(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m=\u001b[39mattempt_load(weights, device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'select_device' is not defined"
     ]
    }
   ],
   "source": [
    "weights='/home/aarke/runs/detect/train13/weights/best.pt'\n",
    "device = select_device('cuda')\n",
    "model=attempt_load(weights, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'/home/aarke/Coding/Trees/Dataset/train/images/101_trees_jpg.rf.853a8cc7086f2ed3b117faa65c546153.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img=cv2.resize(img, (640,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img).permute(2,0,1).float()/255.0\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = non_max_suppression(pred, 0.5, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'tree'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class='tree'\n",
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/Trees/detection.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     x1, y1, x2, y2 \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, det[:\u001b[39m4\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255.0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# img=img.squeeze(0)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# img=img.numpy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m# Draw the bounding box and label on the image\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     cv2\u001b[39m.\u001b[39;49mrectangle(img, (x1, y1), (x2, y2), (\u001b[39m0\u001b[39;49m, \u001b[39m255\u001b[39;49m, \u001b[39m0\u001b[39;49m), \u001b[39m2\u001b[39;49m)  \u001b[39m# Green rectangle\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#             # Add a label near the bounding box\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aarke/Coding/Trees/detection.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtarget_class\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mdet[\u001b[39m4\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "class_count = 0\n",
    "\n",
    "    # Iterate through the detection results\n",
    "for det in pred[0]:\n",
    "        # if det[-1] == class_id:  # Check if the detected class matches the desired class\n",
    "    class_count += 1\n",
    "    x1, y1, x2, y2 = map(int, det[:4]*255.0)\n",
    "    # img=img.squeeze(0)\n",
    "    # img=img.numpy()\n",
    "            # Draw the bounding box and label on the image\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green rectangle\n",
    "\n",
    "#             # Add a label near the bounding box\n",
    "    label = f'{target_class} ({det[4]:.2f})'\n",
    "    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "print(f\"Number of {target_class}s in the image: {class_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/potato_proj/detection.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49m__version__\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aarke/Coding/potato_proj/detection.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aarke/Coding/potato_proj/detection.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39;49m__version__\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
